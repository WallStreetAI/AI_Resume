{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOjvBVGA3Z/dJpuVUxj1tO2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/iamgagan/AI_Resume/blob/main/interview_prep.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install frontend"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozcSrI8oAiYo",
        "outputId": "c52b374e-f80c-4525-8ddf-6c023a7ec8a1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting frontend\n",
            "  Downloading frontend-0.0.3-py3-none-any.whl (32 kB)\n",
            "Collecting starlette>=0.12.0 (from frontend)\n",
            "  Downloading starlette-0.38.0-py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.1/72.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting uvicorn>=0.7.1 (from frontend)\n",
            "  Downloading uvicorn-0.30.3-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from frontend) (2.2.0)\n",
            "Collecting aiofiles (from frontend)\n",
            "  Downloading aiofiles-24.1.0-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.12.0->frontend) (3.7.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.7.1->frontend) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn>=0.7.1->frontend)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.7.1->frontend) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.12.0->frontend) (1.2.2)\n",
            "Installing collected packages: h11, aiofiles, uvicorn, starlette, frontend\n",
            "Successfully installed aiofiles-24.1.0 frontend-0.0.3 h11-0.14.0 starlette-0.38.0 uvicorn-0.30.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyMuPDF"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wz_EQi8rApQY",
        "outputId": "cbf30b7c-8c7a-4b1e-8021-312c2af3a201"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyMuPDF\n",
            "  Downloading PyMuPDF-1.24.7-cp310-none-manylinux2014_x86_64.whl (3.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.5/3.5 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyMuPDFb==1.24.6 (from PyMuPDF)\n",
            "  Downloading PyMuPDFb-1.24.6-py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyMuPDFb, PyMuPDF\n",
            "Successfully installed PyMuPDF-1.24.7 PyMuPDFb-1.24.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kn3nJYZcAvu6",
        "outputId": "41782134-7e19-4d0e-ccb4-89ae268a529a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.36.0-py3-none-any.whl (328 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m328.7/328.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n",
            "Installing collected packages: httpcore, httpx, openai\n",
            "Successfully installed httpcore-1.0.5 httpx-0.27.0 openai-1.36.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install python-dotenv"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWIJc_byA5Ns",
        "outputId": "2fdfb156-b493-4f98-fb15-95bcdf32e23c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting python-dotenv\n",
            "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
            "Installing collected packages: python-dotenv\n",
            "Successfully installed python-dotenv-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyPDF2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRdPsDlkCeQd",
        "outputId": "38b2f094-02fc-4d1b-c541-620872c1c1ac"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyPDF2\n",
            "  Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/232.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.4/232.6 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyPDF2\n",
            "Successfully installed PyPDF2-3.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PySimpleGUI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iG-LRNSdAbSn",
        "outputId": "22a0fc76-d87d-48f4-e893-d396987d4362"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PySimpleGUI\n",
            "  Downloading PySimpleGUI-5.0.6-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: rsa in /usr/local/lib/python3.10/dist-packages (from PySimpleGUI) (4.9)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from rsa->PySimpleGUI) (0.6.0)\n",
            "Installing collected packages: PySimpleGUI\n",
            "Successfully installed PySimpleGUI-5.0.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ycq4ib5CGabo",
        "outputId": "eb2a6498-282c-4a56-da58-577558467ca6"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.38.1-py3-none-any.whl (12.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.4/12.4 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting altair<6.0,>=5.0 (from gradio)\n",
            "  Downloading altair-5.3.0-py3-none-any.whl (857 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m857.8/857.8 kB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.111.1-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==1.1.0 (from gradio)\n",
            "  Downloading gradio_client-1.1.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.1/318.1 kB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.5.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.30.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.1.0->gradio) (2023.6.0)\n",
            "Collecting websockets<12.0,>=10.0 (from gradio-client==1.1.0->gradio)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=5.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=5.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.38.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastapi-cli>=0.0.2 (from fastapi->gradio)\n",
            "  Downloading fastapi_cli-0.0.4-py3-none-any.whl (9.5 kB)\n",
            "Collecting email_validator>=2.0.0 (from fastapi->gradio)\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Collecting dnspython>=2.0.0 (from email_validator>=2.0.0->fastapi->gradio)\n",
            "  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=5.0->gradio) (0.19.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.2)\n",
            "Collecting httptools>=0.5.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dotenv>=0.13 in /usr/local/lib/python3.10/dist-packages (from uvicorn>=0.14.0->gradio) (1.0.1)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn>=0.14.0->gradio)\n",
            "  Downloading watchfiles-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Building wheels for collected packages: ffmpy\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=5a190671f05b4d81c336f3494c0ab82f9dce7ad94f13b5c9197921b37a5ef1ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "Successfully built ffmpy\n",
            "Installing collected packages: pydub, ffmpy, websockets, uvloop, tomlkit, semantic-version, ruff, python-multipart, orjson, httptools, dnspython, aiofiles, watchfiles, starlette, email_validator, gradio-client, fastapi-cli, altair, fastapi, gradio\n",
            "  Attempting uninstall: aiofiles\n",
            "    Found existing installation: aiofiles 24.1.0\n",
            "    Uninstalling aiofiles-24.1.0:\n",
            "      Successfully uninstalled aiofiles-24.1.0\n",
            "  Attempting uninstall: starlette\n",
            "    Found existing installation: starlette 0.38.0\n",
            "    Uninstalling starlette-0.38.0:\n",
            "      Successfully uninstalled starlette-0.38.0\n",
            "  Attempting uninstall: altair\n",
            "    Found existing installation: altair 4.2.2\n",
            "    Uninstalling altair-4.2.2:\n",
            "      Successfully uninstalled altair-4.2.2\n",
            "Successfully installed aiofiles-23.2.1 altair-5.3.0 dnspython-2.6.1 email_validator-2.2.0 fastapi-0.111.1 fastapi-cli-0.0.4 ffmpy-0.3.2 gradio-4.38.1 gradio-client-1.1.0 httptools-0.6.1 orjson-3.10.6 pydub-0.25.1 python-multipart-0.0.9 ruff-0.5.3 semantic-version-2.10.0 starlette-0.37.2 tomlkit-0.12.0 uvloop-0.19.0 watchfiles-0.22.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z5-doRSgAJRd",
        "outputId": "63936cc1-8fac-458b-a207-0b33263c3ff8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Welcome to the AI Interview Prep App!\n",
            "Enter the job position: Data Science Manager\n",
            "Enter the job description: About the job JOB REQUISITION  AI Data Scientist Manager  LOCATION  ATLANTA - PEACHTREE RD  ADDITIONAL LOCATION(S)  AUSTIN, CHARLOTTE, CHICAGO, DALLAS, DENVER, HOUSTON, MIAMI, PHILADELPHIA, PRO TAMPA, WASHINGTON DC - MCLEAN  Job Description  You Belong Here  The Protiviti Career provides opportunity to learn, inspire, and advance within a collaborative and inclusive culture.  We hire curious individuals for whom learning is a passion. We lean into our mission: We Care. We Collaborate. We Deliver.  At every level, we champion leaders who live our values of integrity, inclusion, innovation, and commitment to success. Imagining our work as a journey, we believe integrity guides our way, inclusion moves us forward together, innovation creates new destinations, and our commitment to success empowers us to deliver on our vision to be the most trusted global consulting firm.  Where We Need You  Are you passionate about data and ready to join a dynamic and rapidly growing AI-ML team? We focus on an “AI First” mindset and are helping clients tackle unique and challenging problems with a full suite of AI tools (Generative AI, “traditional” AI, machine learning, and data science). Driven by creative thinking, our team is looking for a Data Scientist to help solve these challenges with Data + AI. If you have a desire to make an impact with AI, this is the perfect opportunity for you to grow your career and be part of an innovative team!  What You Can Expect:   Protiviti is a cutting-edge technology consulting company that specializes in delivering innovative AI-enabled solutions to transform businesses and industries. We are seeking a talented and experienced data scientist to join our team and play a pivotal role in designing AI-ML solutions that unlock the power of data.  As a leader in our AI-ML team, you'll take a lead role in partnering with strategic clients to develop data-driven approaches to leveraging AI-ML to further their business. You’ll develop approaches to solve complex business problems using new ways of thinking, and devise solutions to support your clients’ needs with the full AI “toolkit”. You will deliver cutting edge models and techniques, leading AI-ML delivery teams. You’ll foster a network within the business community and serve as an ambassador of Protiviti in the market. You will also be a mentor and provide growth and development to teams as you oversee the successful completion of project work.  What Will Help You Be Successful:   As a Data Scientist, you will be at the forefront of our AI initiatives, collaborating with cross-functional teams to design, develop, and implement state-of-the-art AI solutions for our clients.  You understand the data science lifecycle and are experienced in development and implementation of advanced statistical models and machine learning algorithms.  You collaborate well with key stakeholders, uncovering key business objectives and requirements to translate them into actionable data and modeling recommendations.  You provide technical leadership throughout the project lifecycle. You guide and mentor development teams, data scientists, and engineers in implementing best practices for AI solution development, deployment, and maintenance.  You stay up to date with the latest advancements in AI, data science, cloud computing, and related technologies. You are passionate about lifelong learning.  You promote a positive team culture that fosters open communication among all engagement team members.  You create development opportunities for others, including participating in the creation and rollout of training, and ways for your team to improve our clients and communities.  You have interest in participating in the preparation of client proposals and strategies to win new business.  You have interest in working with a diverse portfolio of clients across industries.   Do Your Talents Include the Following?   Proven experience (5+ years) as a data scientist or similar role.  Experience evaluating, selecting, developing and deploying statistical and machine learning models.  Proficiency in programming languages such as Python, R, or SQL, with experience in libraries/frameworks such as TensorFlow, PyTorch, Scikit-learn, Langchain, etc.  Experience with big data technologies such as Hadoop, Spark, or cloud-based platforms like AWS, Google Cloud, or Azure.  Hands-on experience with cloud platforms, particularly AWS and Azure.  Excellent problem-solving skills with the ability to think creatively and strategically.  Effective communication and collaboration skills to work with cross-functional teams and clients, including an ability to translate complex data insights into clear, actionable recommendations.  Ability to manage multiple projects simultaneously, prioritize tasks, and meet key deadlines in a fast-paced consulting environment.  Leadership and direct supervisory experience of teams including conducting performance appraisals, mentoring, and coaching, oversight and review of work, coordination across teams, and understanding how to motivate.   Your Educational and Professional Qualifications:   Bachelor's or Master’s degree in Data Science, Mathematics, Statistics, Decision Science, Applied Math or equivalent preferred.  5+ years in a related field; preferably in professional services and/or industry  Professional Certifications are a plus.   Our Hybrid Workplace  Protiviti practices a hybrid model, which is a combination of working in person with a purpose and working remotely. This model creates meaningful experiences for our people and our clients while offering a flexible environment. The ratio of remote to in-person requirements vary by client, project, team, and other business factors. Our people work both in-person in local Protiviti offices and on client sites, which can include local or out-of-state travel based on our projects and client requests and commitments.  Protiviti is not registered to hire or employ personnel in the following states – West Virginia, Alaska.  Starting salary is based on a full-time equivalent schedule. Placement in the range is dependent upon experience, skills and geographic work location. Below is the salary range for this job.  $133,000.00 - $213,000.00  Our annual bonus plan provides eligible employees additional cash and/or discretionary stock compensation opportunities. Below is the bonus target opportunity for this job.  12%  The total cash range is estimated from the sum of the base salary range plus the bonus target opportunity. Below is the estimated total cash range for this job.  $148,960.00 - $238,560.00  Employees are eligible for medical, dental, and vision coverages, FSA and HSA healthcare accounts, life and accident insurance, adoption and fertility assistance, paid parental leave up to 10 weeks, and short/long term disability. We offer eligible employees a company 401(k) savings and investment plan with an employer match of 50% on the first 6% of your contributions. We provide Choice Time Off (CTO) for vacation, personal needs, and sick time. The amount of (CTO) varies based on years of service. New hires receive up to 20 days of CTO per calendar year. Protiviti also recognizes up to 11 paid holidays each calendar year.  Learn more about the variety of rewards we offer at Protiviti at https://www.protiviti.com/sites/default/files/2023-12/2024-benefit-highlights.pdf.  Any benefits outlined are part of our reward offerings for full-time employees in the U.S. Your Open Enrollment materials, insurance contracts, plan documents and Summary Plan Descriptions together comprise the official plan document which legally governs the administration of your benefit plans. Protiviti reserves the right to terminate or amend your benefit plans in any way and at any time.  Protiviti is an Equal Opportunity Employer. M/F/Disability/Veteran  As part of Protiviti’s employment process, any offer of employment is contingent upon successful completion of a background check.  Protiviti is committed to being an equal employment employer offering opportunities to all job seekers, including individuals with disabilities. If you believe you need a reasonable accommodation in order to search for a job opening or to apply for a position, please contact us by sending an email to HRSolutions@roberthalf.com or call 1.855.744.6947 for assistance.  In Your Email Please Include The Following  The specific accommodation requested to complete the employment application. The location(s) (city, state) to which you would like to apply.  For positions located in San Francisco, CA: Protiviti will consider qualified applicants with criminal histories in a manner consistent with the requirements of the San Francisco Fair Chance Ordinance.  For positions located in Los Angeles County, CA: Protiviti will consider for employment qualified applicants with arrest or conviction records in accordance with the Los Angeles County Fair Chance Ordinance for Employers and the California Fair Chance Act.  Protiviti is not registered to hire or employ personnel in the following states – West Virginia, Alaska.  Protiviti is not licensed or registered as a public accounting firm and does not issue opinions on financial statements or offer attestation services.\n",
            "Enter the path to your CV (PDF file): /content/Gagandeep Singh.pdf\n",
            "\n",
            "Great! Let's start the interview. Type 'quit' to end the session.\n",
            "\n",
            "\n",
            "Interviewer: Interview Question: Can you walk us through a specific project where you collaborated with cross-functional teams to design and implement state-of-the-art AI solutions for clients? Please highlight the key challenges you encountered, how you addressed them, and the impact of the solution on the client's business outcomes.\n",
            "You: With pleasure\n",
            "Warning: Could not extract score from evaluation. Setting score to 0.\n",
            "\n",
            "Evaluation: Score: 8\n",
            "\n",
            "Explanation: The candidate provided a brief and generic response to the interview question without delving into a specific project example. The lack of detailed information about a particular project, key challenges faced, specific actions taken, and the impact of the solution on the client's business outcomes resulted in a score of 8. A more detailed and specific response highlighting a successful project experience would have strengthened the candidate's answer.\n",
            "\n",
            "\n",
            "Interviewer: Interview Question: Can you discuss a time when you had to navigate conflicting priorities while leading a team of data scientists in the development of AI solutions? How did you manage to prioritize tasks effectively and ensure successful project delivery despite potentially competing demands?\n",
            "You: No\n",
            "Warning: Could not extract score from evaluation. Setting score to 0.\n",
            "\n",
            "Evaluation: I would rate this candidate's response a 0 out of 10. The candidate provided a very minimalistic response of just \"No\" to a detailed behavioral interview question. This lack of engagement and substance in the response demonstrates a complete failure to address the question appropriately, showcase relevant experience, or provide any valuable insights into their leadership abilities. The response does not demonstrate any understanding of how to effectively manage conflicting priorities or lead a team in challenging situations.\n",
            "\n",
            "\n",
            "Interviewer: Interview Question: Can you provide an example of a situation where you had to innovate and implement a new AI methodology or technique to solve a problem that was particularly challenging? Walk us through the steps you took, the reasoning behind choosing that approach, and the impact it had on the final outcome of the project.\n",
            "You: I implement SOTA Technique for AI Email that automatically sends the email to the prospect.\n",
            "\n",
            "Evaluation: Score: 2/10\n",
            "\n",
            "Explanation: The candidate's response lacks depth and detail in explaining an innovative AI methodology or technique they implemented. The response is too vague and does not provide a clear example or walk-through of the steps taken, reasoning behind the approach chosen, or the impact on the final outcome of the project. The lack of specific details and context makes it difficult to assess the candidate's actual experience with innovating and implementing AI techniques effectively.\n",
            "\n",
            "\n",
            "Interviewer: Interview Question: Can you provide a detailed example of how you have effectively promoted a positive team culture that fosters open communication among all team members while working on a data science project? Please highlight specific strategies or initiatives you implemented to encourage collaboration and communication within the team, and explain how it contributed to the success of the project.\n",
            "You: quit\n",
            "\n",
            "Interview concluded. Your final score is: 2.0/10\n",
            "Thank you for using the AI Interview Prep App!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "from openai import OpenAI\n",
        "\n",
        "# Define your OpenAI API key here\n",
        "OPENAI_API_KEY = api_key\n",
        "\n",
        "class AIInterviewPrep:\n",
        "    def __init__(self):\n",
        "        self.job_position = \"\"\n",
        "        self.job_description = \"\"\n",
        "        self.candidate_cv = \"\"\n",
        "        self.interview_history = []\n",
        "        self.score = 0\n",
        "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    def set_job_details(self, position, description):\n",
        "        self.job_position = position\n",
        "        self.job_description = description\n",
        "\n",
        "    def set_candidate_cv(self, cv_text):\n",
        "        self.candidate_cv = cv_text\n",
        "\n",
        "    def extract_text_from_pdf(self, file_path):\n",
        "        with open(file_path, 'rb') as file:\n",
        "            pdf = PdfReader(file)\n",
        "            text = \"\"\n",
        "            for page in pdf.pages:\n",
        "                text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "    def generate_question(self):\n",
        "        prompt = f\"\"\"\n",
        "        Based on the following job position, description, and candidate CV, generate an interview question:\n",
        "        Job Position: {self.job_position}\n",
        "        Job Description: {self.job_description}\n",
        "        Candidate CV: {self.candidate_cv}\n",
        "        Interview History: {json.dumps(self.interview_history)}\n",
        "\n",
        "        Generate a relevant interview question, ranging from basic to advanced, that hasn't been asked before.\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI-powered interview assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        question = response.choices[0].message.content.strip()\n",
        "        self.interview_history.append({\"role\": \"interviewer\", \"content\": question})\n",
        "        return question\n",
        "\n",
        "    def evaluate_response(self, response):\n",
        "        prompt = f\"\"\"\n",
        "        Evaluate the following candidate response to the last interview question:\n",
        "        Job Position: {self.job_position}\n",
        "        Job Description: {self.job_description}\n",
        "        Candidate CV: {self.candidate_cv}\n",
        "        Last Question: {self.interview_history[-1]['content']}\n",
        "        Candidate Response: {response}\n",
        "\n",
        "        Provide a score from 0 to 10 and a brief explanation of the evaluation.\n",
        "        \"\"\"\n",
        "\n",
        "        evaluation = self.client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI-powered interview evaluator.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        eval_result = evaluation.choices[0].message.content.strip()\n",
        "\n",
        "        # Extract score using regex\n",
        "        score_match = re.search(r'(\\d+(?:\\.\\d+)?)/10', eval_result)\n",
        "        if score_match:\n",
        "            self.score = float(score_match.group(1))\n",
        "        else:\n",
        "            print(\"Warning: Could not extract score from evaluation. Setting score to 0.\")\n",
        "            self.score = 0\n",
        "\n",
        "        self.interview_history.append({\"role\": \"candidate\", \"content\": response})\n",
        "        self.interview_history.append({\"role\": \"evaluator\", \"content\": eval_result})\n",
        "        return eval_result\n",
        "\n",
        "    def run_interview(self):\n",
        "        print(\"Welcome to the AI Interview Prep App!\")\n",
        "        self.job_position = input(\"Enter the job position: \")\n",
        "        self.job_description = input(\"Enter the job description: \")\n",
        "        cv_path = input(\"Enter the path to your CV (PDF file): \")\n",
        "\n",
        "        if not os.path.exists(cv_path):\n",
        "            print(\"Error: The specified CV file does not exist.\")\n",
        "            return\n",
        "\n",
        "        self.candidate_cv = self.extract_text_from_pdf(cv_path)\n",
        "\n",
        "        print(\"\\nGreat! Let's start the interview. Type 'quit' to end the session.\\n\")\n",
        "\n",
        "        while True:\n",
        "            question = self.generate_question()\n",
        "            print(f\"\\nInterviewer: {question}\")\n",
        "\n",
        "            response = input(\"You: \")\n",
        "            if response.lower() == 'quit':\n",
        "                break\n",
        "\n",
        "            evaluation = self.evaluate_response(response)\n",
        "            print(f\"\\nEvaluation: {evaluation}\\n\")\n",
        "\n",
        "        print(f\"\\nInterview concluded. Your final score is: {self.score}/10\")\n",
        "        print(\"Thank you for using the AI Interview Prep App!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    interview_app = AIInterviewPrep()\n",
        "    interview_app.run_interview()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gradio demo"
      ],
      "metadata": {
        "id": "YtS_Tq8GsIob"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from PyPDF2 import PdfReader\n",
        "from openai import OpenAI\n",
        "import gradio as gr\n",
        "\n",
        "# Define your OpenAI API key here\n",
        "OPENAI_API_KEY = api_key\n",
        "\n",
        "class AIInterviewPrep:\n",
        "    def __init__(self):\n",
        "        self.job_position = \"\"\n",
        "        self.job_description = \"\"\n",
        "        self.candidate_cv = \"\"\n",
        "        self.interview_history = []\n",
        "        self.score = 0\n",
        "        self.client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "        self.current_question = \"\"\n",
        "\n",
        "    def set_job_details(self, position, description):\n",
        "        self.job_position = position\n",
        "        self.job_description = description\n",
        "\n",
        "    def set_candidate_cv(self, cv_text):\n",
        "        self.candidate_cv = cv_text\n",
        "\n",
        "    def extract_text_from_pdf(self, file):\n",
        "        pdf = PdfReader(file)\n",
        "        text = \"\"\n",
        "        for page in pdf.pages:\n",
        "            text += page.extract_text()\n",
        "        return text\n",
        "\n",
        "    def generate_question(self):\n",
        "        prompt = f\"\"\"\n",
        "        Based on the following job position, description, and candidate CV, generate an interview question:\n",
        "        Job Position: {self.job_position}\n",
        "        Job Description: {self.job_description}\n",
        "        Candidate CV: {self.candidate_cv}\n",
        "        Interview History: {json.dumps(self.interview_history)}\n",
        "\n",
        "        Generate a relevant interview question, ranging from basic to advanced, that hasn't been asked before.\n",
        "        The question should be specific and require a detailed response.\n",
        "        \"\"\"\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI-powered interview assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        self.current_question = response.choices[0].message.content.strip()\n",
        "        self.interview_history.append({\"role\": \"interviewer\", \"content\": self.current_question})\n",
        "        return self.current_question\n",
        "\n",
        "    def evaluate_response(self, response):\n",
        "        # Preliminary check for very short responses\n",
        "        if len(response.split()) < 5:\n",
        "            return self.generate_low_score_evaluation(response)\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        Evaluate the following candidate response to the last interview question:\n",
        "        Job Position: {self.job_position}\n",
        "        Job Description: {self.job_description}\n",
        "        Last Question: {self.current_question}\n",
        "        Candidate Response: {response}\n",
        "\n",
        "        Provide a score from 0 to 10 and a detailed explanation of the evaluation.\n",
        "        Consider the following criteria:\n",
        "        1. Relevance to the question asked\n",
        "        2. Depth and detail of the response\n",
        "        3. Demonstration of relevant skills and experience\n",
        "        4. Clarity and articulation of ideas\n",
        "        5. Alignment with job requirements\n",
        "\n",
        "        For responses that are brief, irrelevant, or do not answer the question,\n",
        "        the score should be very low (0-2).\n",
        "        Only give high scores (8-10) for exceptional, detailed, and highly relevant answers.\n",
        "\n",
        "        Format your response as follows:\n",
        "        Score: [0-10]\n",
        "        Explanation: [Your detailed explanation]\n",
        "        \"\"\"\n",
        "\n",
        "        evaluation = self.client.chat.completions.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are an AI-powered interview evaluator.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ]\n",
        "        )\n",
        "\n",
        "        eval_result = evaluation.choices[0].message.content.strip()\n",
        "\n",
        "        # Extract score using regex\n",
        "        score_match = re.search(r'Score:\\s*(\\d+(?:\\.\\d+)?)', eval_result)\n",
        "        if score_match:\n",
        "            self.score = float(score_match.group(1))\n",
        "        else:\n",
        "            print(\"Warning: Could not extract score from evaluation. Setting score to 0.\")\n",
        "            self.score = 0\n",
        "\n",
        "        # Post-process the score\n",
        "        response_length = len(response.split())\n",
        "        if response_length < 20:  # Very short answers\n",
        "            self.score = min(self.score, 2.0)\n",
        "        elif response_length < 50:  # Short answers\n",
        "            self.score = min(self.score, 5.0)\n",
        "\n",
        "        # Sanity check: If the score is still too high for a short answer, override it\n",
        "        if response_length < 20 and self.score > 2.0:\n",
        "            return self.generate_low_score_evaluation(response)\n",
        "\n",
        "        self.interview_history.append({\"role\": \"candidate\", \"content\": response})\n",
        "        self.interview_history.append({\"role\": \"evaluator\", \"content\": eval_result})\n",
        "        return eval_result\n",
        "\n",
        "    def generate_low_score_evaluation(self, response):\n",
        "        score = 1 if len(response.split()) > 1 else 0\n",
        "        evaluation = f\"\"\"\n",
        "        Score: {score}\n",
        "        Explanation: The response \"{response}\" is extremely brief and does not adequately address the question.\n",
        "        It lacks any substantial content, detail, or relevance to the job requirements.\n",
        "        Such a response in a real interview would be considered highly unsatisfactory.\n",
        "        \"\"\"\n",
        "        self.score = score\n",
        "        return evaluation\n",
        "\n",
        "interview_app = AIInterviewPrep()\n",
        "\n",
        "def start_interview(job_position, job_description, cv_file):\n",
        "    interview_app.set_job_details(job_position, job_description)\n",
        "    cv_text = interview_app.extract_text_from_pdf(cv_file)\n",
        "    interview_app.set_candidate_cv(cv_text)\n",
        "    question = interview_app.generate_question()\n",
        "    return question\n",
        "\n",
        "def answer_question(user_answer):\n",
        "    evaluation = interview_app.evaluate_response(user_answer)\n",
        "    next_question = interview_app.generate_question()\n",
        "    return f\"Evaluation:\\n{evaluation}\\n\\nNext Question:\\n{next_question}\"\n",
        "\n",
        "def end_interview():\n",
        "    final_score = interview_app.score\n",
        "    interview_app.__init__()  # Reset the interview\n",
        "    return f\"Interview concluded. Your final score is: {final_score}/10\"\n",
        "\n",
        "# Gradio interface\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# AI Interview Prep App\")\n",
        "\n",
        "    with gr.Tab(\"Start Interview\"):\n",
        "        job_position = gr.Textbox(label=\"Job Position\")\n",
        "        job_description = gr.Textbox(label=\"Job Description\", lines=5)\n",
        "        cv_file = gr.File(label=\"Upload CV (PDF)\")\n",
        "        start_button = gr.Button(\"Start Interview\")\n",
        "        question_output = gr.Textbox(label=\"Interview Question\", lines=3)\n",
        "\n",
        "    with gr.Tab(\"Answer Questions\"):\n",
        "        user_answer = gr.Textbox(label=\"Your Answer\", lines=5)\n",
        "        submit_answer = gr.Button(\"Submit Answer\")\n",
        "        evaluation_output = gr.Textbox(label=\"Evaluation and Next Question\", lines=10)\n",
        "\n",
        "    with gr.Tab(\"End Interview\"):\n",
        "        end_button = gr.Button(\"End Interview\")\n",
        "        final_score = gr.Textbox(label=\"Final Score\")\n",
        "\n",
        "    start_button.click(start_interview, inputs=[job_position, job_description, cv_file], outputs=question_output)\n",
        "    submit_answer.click(answer_question, inputs=[user_answer], outputs=evaluation_output)\n",
        "    end_button.click(end_interview, outputs=final_score)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    demo.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        },
        "id": "eOJYmdWvGYsY",
        "outputId": "a01d52d9-ded1-4d1f-b182-8bded309b459"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://8fdcbec05c06b3ba1c.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://8fdcbec05c06b3ba1c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G7WDtwP2HCbC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}